{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "from future.utils import iteritems\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pymysql\n",
    "from gensim.models import word2vec\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "if sys.version_info <= (2,7):\n",
    "    reload(sys)\n",
    "    sys.setdefaultencoding('utf-8')\n",
    "import konlpy\n",
    "from konlpy.tag import Kkma, Okt, Hannanum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data = pd.read_csv('mixver9.txt', encoding='utf-8', header= None)\n",
    "documents = [' '.join(i[0].split(' ')[1:]) for i in article_data.values]\n",
    "\n",
    "as_one = ''\n",
    "for document in documents:\n",
    "    as_one = as_one + ' ' + document\n",
    "words = as_one.split()\n",
    "\n",
    "counts = Counter(words)\n",
    "\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "\n",
    "word2idx = {word.encode(\"utf8\").decode(\"utf8\"): ii for ii, word in enumerate(vocab,1)}\n",
    "\n",
    "idx2word = {ii: word for ii, word in enumerate(vocab)}\n",
    "\n",
    "V = len(word2idx)\n",
    "N = len(documents)\n",
    "\n",
    "tf = CountVectorizer()\n",
    "\n",
    "tf.fit_transform(documents)\n",
    "\n",
    "tf.fit_transform(documents)[0:1].toarray()\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features = 1000, max_df=1, min_df=0)\n",
    "\n",
    "#generate tf-idf term-document matrix\n",
    "A_tfidf_sp = tfidf.fit_transform(documents)  #size D x V\n",
    "\n",
    "tfidf_dict = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "konlpy version = 0.5.2\n"
     ]
    }
   ],
   "source": [
    "kkma = Kkma()\n",
    "okt = Okt()\n",
    "hannanum = Hannanum()\n",
    "print('konlpy version = %s' % konlpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-42-54d92403bdc6>, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-42-54d92403bdc6>\"\u001b[1;36m, line \u001b[1;32m33\u001b[0m\n\u001b[1;33m    else if :\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "conn = pymysql.connect(host='127.0.0.1', port=3306, user='root', password='0000',db='test', charset='utf8')\n",
    "curs = conn.cursor()\n",
    "\n",
    "project_title = '꿈을 담다. 꿈 해몽 카드 모르몽'\n",
    "project_category ='디자인'\n",
    "\n",
    "tokenized_project_title = set(okt.nouns(project_title))\n",
    "selected_word=[]\n",
    "\n",
    "for i in tokenized_project_title:\n",
    "    if i in tfidf_dict:\n",
    "        selected_word.append(i)\n",
    "        continue\n",
    "model = word2vec.Word2Vec.load(\"NaverMovie29.model\")\n",
    "\n",
    "print(selected_word)\n",
    "\n",
    "t_cnt =0\n",
    "w_cnt = 0\n",
    "\n",
    "for i in selected_word:\n",
    "    similar_word=model.wv.most_similar(positive=[i],topn=5)\n",
    "    print(similar_word)\n",
    "    for j in similar_word:\n",
    "        sql = 'select pagename from test.crawl where category=\"%s\" and title like \"%%%s%%\" and achieve>100;'%(project_category,j[0])\n",
    "        curs.execute(sql)\n",
    "        pagename = curs.fetchall()\n",
    "        print(pagename)\n",
    "        print(type(pagename))\n",
    "        for k in pagename:\n",
    "            if k[0] == 'tumblbug':\n",
    "                t_cnt+=1\n",
    "            elif k[-]:\n",
    "                \n",
    "                w_cnt+=1\n",
    "        \n",
    "\n",
    "print(t_cnt, w_cnt)\n",
    "if t_cnt > w_cnt:\n",
    "    print(\"tumblbug\")\n",
    "elif t_cnt == w_cnt:\n",
    "    print(\"same\")\n",
    "else:\n",
    "    print(\"wadiz\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymysql.connect(host='127.0.0.1', port=3306, user='root', password='0000',db='test', charset='utf8')\n",
    "\n",
    "curs = conn.cursor()\n",
    "\n",
    "\n",
    "#print('꼬꼬마 명사: ', kkma.nouns(sent))\n",
    "#print(okt.nouns(sent))\n",
    "#print('한나눔 명사: ', hannanum.nouns(sent))\n",
    "username=\"박가영\"\n",
    "sql = \"select distinct trim(I.title) from test.user_info I, test.crawl C where username like '%s' and C.title = I.title;\"%username\n",
    "#sql1 = \"select distinct I.title, C.category from test.user_info I, test.crawl C where username like '%s' and C.title = I.title;\"%username\n",
    "\n",
    "curs.execute(sql)\n",
    "sent = curs.fetchall()\n",
    "\n",
    "\"\"\"\n",
    "curs.execute(sql1)\n",
    "title_with_category = curs.fetchall()\n",
    "print(\"=======title with category=========\")\n",
    "#print(title_with_category)\n",
    "#for i in title_with_category:\n",
    "#    print(i[1])\n",
    "print(\"=======title with category=========\")\n",
    "\"\"\"\n",
    "noun_set = set(okt.nouns(str(sent)))\n",
    "selected_word = []\n",
    "#print(sent)\n",
    "sent_list = list(sent)\n",
    "sent_list2 = []\n",
    "for i in sent_list:\n",
    "    sent_list2.append(list(i))\n",
    "#print(sent_list2)\n",
    "#selected_word : tokenized word from user's funding title list\n",
    "for i in noun_set:\n",
    "    if i in tfidf_dict:\n",
    "        selected_word.append(i)\n",
    "        continue\n",
    "final_word_list = []\n",
    "category_list=[]\n",
    "#final_word_list : selected words\n",
    "print(\"=======category list=======\")\n",
    "for i in selected_word:\n",
    "    sql3 = \"select distinct I.title, C.category from test.user_info I, test.crawl C where username like '{username}' and C.title = I.title and I.title like '%%{word}%%';\".format(username=username, word=i);\n",
    "    curs.execute(sql3)\n",
    "    rows = curs.fetchall()\n",
    "    #print(rows)\n",
    "    \n",
    "    for j in rows:\n",
    "        if i in j[0]:\n",
    "            final_word_list.append(i)\n",
    "            category_list.append(j[1])\n",
    "            #print(i, j[1])\n",
    "print(\"=======category list=======\")  \n",
    "\n",
    "model = word2vec.Word2Vec.load(\"NaverMovie29.model\")\n",
    "word_len = len(final_word_list)\n",
    "category_len = len(category_list)\n",
    "\n",
    "final_projects=[]\n",
    "similar_word_list=[]\n",
    "for i in tqdm(range(word_len)):\n",
    "    print(\"<<key word: \"+final_word_list[i], category_list[i]+\">>\")\n",
    "    print()\n",
    "    similar_word=model.wv.most_similar(positive=[final_word_list[i]],topn=5)\n",
    "    for j in similar_word:\n",
    "        if len(j[0])==1:\n",
    "            continue\n",
    "        else:\n",
    "            print(j[0])\n",
    "            sql = \"select DISTINCT pagename, category, trim(title) from test.crawl where title like '%%%s%%'\" %j[0]\n",
    "            curs.execute(sql)\n",
    "            words = curs.fetchall()\n",
    "            conn.commit()\n",
    "            #print(words)\n",
    "            length = len(words)\n",
    "            if length>3:\n",
    "                length = 3\n",
    "            #print(length)\n",
    "            cnt1=0\n",
    "            cnt2=0\n",
    "            for k in range(0,length):\n",
    "                tmp=[]\n",
    "                tmp.append(''.join(list(words[k][2])))\n",
    "                if words[k][1] == category_list[i] and tmp not in sent_list2 :\n",
    "                    print('추천할 수 있는 프로젝트 ', end='')\n",
    "                    cnt1+=1\n",
    "                    print(cnt1)\n",
    "                    final_projects.append(words[k])\n",
    "\n",
    "        \n",
    "        print()   \n",
    "\n",
    "\n",
    "final_projects_set = set(final_projects)\n",
    "for i in final_projects_set:\n",
    "    print(i)\n",
    "print(len(final_projects_set))\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
